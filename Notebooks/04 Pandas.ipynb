{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "The panadas module is one of the most powerful tools for data analysis.  Pandas was designed to work with tabular and heterogeneous data.  It is standard to use the alias ``pd`` when importing pandas.\n",
    "~~~\n",
    "import pandas as pd\n",
    "~~~\n",
    "I usually import numpy at the same time since pandas and numpy are often used in tandem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two main data structures that we will use from pandas are the *Series* and the *DataFrame*.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "A Series is a one-dimensional array-like object containing a sequence of values and an associated array of data labels, called the *index*.  \n",
    "\n",
    "### Creating a Series\n",
    "A Series can be created from a list, a numpy ndarray, or a dictionary using the function ``pd.Series``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [45, 17, 16, 44, 28]  \n",
    "labels = ['Utah', 'Ohio', 'Tennessee', 'Wyoming', 'Texas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data = my_list, index = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'Utah':45, 'Ohio':17, 'Tennessee':16, 'Wyoming':44, 'Texas':28}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can kind of think about a Series as an ordered dictionary where the labels are the key and the data are the values.\n",
    "\n",
    "The data in a Series need not be numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "DataFrames are the main data structure of pandas and were directly inspired by the R programming language.  DataFrames are a bunch of Series objects put together to share the same (row) index.  A DataFrame has both a row and a column index.  \n",
    "\n",
    "### Creating DataFrames\n",
    "DataFrames can also be created from lists, dictionaries, or numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(229)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randn(5,4), index='A B C D E'.split(), columns='W X Y Z'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using dictionaries, the key will be the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'state':['Utah','Ohio','Tennessee','Wyoming','Texas'], 'order':[45,17,16,44,28], 'min_elev':[2350,455,16,44,28], 'capital':['Salt Lake City','Columbus','Nashville','Cheyenne','Autin']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can turn a column of the data into the index (row name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.index = df2['state']\n",
    "del df2['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection and Indexing\n",
    "\n",
    "There are various ways to get subsets of the data.  In the following ``df`` refers to a DataFrame.\n",
    "\n",
    "#### Selecting columns\n",
    "~~~\n",
    "df['column_name']  # this will produce a Series\n",
    "df.column_name # as long as column_name isn't a python method/attribute (also a Series)\n",
    "df[['column_name']] # this will produce a DataFrame\n",
    "df[['col1', 'col2', 'col3']]\n",
    "~~~\n",
    "\n",
    "#### Selecting row and columns with ``loc`` and ``iloc``\n",
    "~~~\n",
    "df.loc['row_name', 'col_name'] \n",
    "df.iloc['row index', 'col index']\n",
    "~~~\n",
    "\n",
    "``loc`` and ``iloc`` also support slicing.  Note: when slicing with ``loc``, the end point IS including (but not when slicing with ``iloc``.\n",
    "\n",
    "~~~\n",
    "df.loc['row_name1':'row_name2', 'col_name1':'col_name2'] #row_name2 and col_name2 WILL be included\n",
    "df.loc[:, 'col_name1':'col_name2']\n",
    "df.loc['r1':'r2', :]\n",
    "df.loc[['r1','r2','r3'],['c1','c2]] # can also pass lists of index and column names\n",
    "\n",
    "df.iloc[index1:index2, col1:col2] #index2 and col2 will NOT be included\n",
    "~~~\n",
    "\n",
    "#### Selecting rows based on column condition\n",
    "~~~\n",
    "df[df[boolean condition]]\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['B':'D', 'X':'Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:3, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['W','X','Z']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select columns X, Y, and Z where values in W are greater than 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for computing summary and descriptive statistics\n",
    "pandas objects have many reduction / summary statistics methods that extract a single value from the rows or columms of a DataFrame.  See Table 5-8 in *Python for Data Analysis* for a more complete list, but here are a few that are commonly used.\n",
    "\n",
    "`count`: number of non-NA values   \n",
    "`describe`: summary statistics for numerical columns   \n",
    "`min`, `max`: min and max values  \n",
    "`argmin`, `argmax`: index of min and max values ## I'm not sure if this works anymore!?   \n",
    "`idxmin`, `idxmax`: index or column name of min and max values  \n",
    "`sum`: sum of values  \n",
    "`mean`: mean of values  \n",
    "`quantile`: quantile from 0 to 1 of values  \n",
    "`var`: (sample) variance of values  \n",
    "`std`: (sample) standard deviation of values  \n",
    "\n",
    "Most of these functions also take an `axis` argument which specifies whether to reduce over rows or columns: 0 for rows and 1 for columns.   \n",
    "There is also an argument `skipna` which specifies whether or not to skip missing values.  The default is True.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.quantile(.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation and covariance\n",
    "`df.corr()` and `df.cov()` will produce the correlation \\ covariance matrix.  Or two Series can be used to get the correlation (or covariance) with `Series1`.corr(`Series2`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['W'].corr(df['X'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
